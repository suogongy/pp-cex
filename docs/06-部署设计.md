# Web3 CEX 部署设计

## 1. 部署架构设计

### 1.1 部署目标
- **高可用性**: 99.9%系统可用性，支持故障自动转移
- **高性能**: 支持万级并发，毫秒级响应
- **可扩展性**: 支持水平扩展，弹性伸缩
- **安全性**: 网络隔离，安全访问控制
- **可维护性**: 自动化部署，监控告警

### 1.2 部署原则
- **容器化**: Docker容器化部署
- **编排化**: Kubernetes容器编排
- **自动化**: CI/CD自动化流程
- **监控化**: 全链路监控告警
- **标准化**: 标准化部署流程

## 2. 部署架构图

### 2.1 整体部署架构
```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                                  CDN层                                            │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                                 │
│  │  CDN节点1   │  │  CDN节点2   │  │  CDN节点3   │                                 │
│  │  华东       │  │  华南       │  │  华北       │                                 │
│  └─────────────┘  └─────────────┘  └─────────────┘                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
                                        │
┌─────────────────────────────────────────────────────────────────────────────────┐
│                                  负载均衡层                                       │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                                 │
│  │  SLB主     │  │  SLB备     │  │  WAF防护    │                                 │
│  │  负载均衡   │  │  负载均衡   │  │ Web应用防火墙│                                 │
│  └─────────────┘  └─────────────┘  └─────────────┘                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
                                        │
┌─────────────────────────────────────────────────────────────────────────────────┐
│                                  应用层                                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                                 │
│  │  应用集群1  │  │  应用集群2  │  │  应用集群3  │                                 │
│  │  华东可用区  │  │  华南可用区  │  │  华北可用区  │                                 │
│  └─────────────┘  └─────────────┘  └─────────────┘                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
                                        │
┌─────────────────────────────────────────────────────────────────────────────────┐
│                                  数据层                                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                                 │
│  │  数据库集群  │  │  缓存集群   │  │  消息队列   │                                 │
│  │ MySQL主从   │  │ Redis集群  │  │ RocketMQ    │                                 │
│  └─────────────┘  └─────────────┘  └─────────────┘                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
                                        │
┌─────────────────────────────────────────────────────────────────────────────────┐
│                                  存储层                                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                                 │
│  │  对象存储   │  │  文件存储   │  │  备份存储   │                                 │
│  │ MinIO集群  │  │  NFS存储   │  │  异地备份   │                                 │
│  └─────────────┘  └─────────────┘  └─────────────┘                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
                                        │
┌─────────────────────────────────────────────────────────────────────────────────┐
│                                  监控层                                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                                 │
│  │  监控系统   │  │  日志系统   │  │  告警系统   │                                 │
│  │ Prometheus │  │ ELK Stack  │  │ AlertManager│                                 │
│  └─────────────┘  └─────────────┘  └─────────────┘                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

## 3. 环境规划

### 3.1 环境分类
| 环境 | 用途 | 服务器配置 | 部署方式 | 访问控制 |
|------|------|------------|----------|----------|
| 开发环境 | 开发测试 | 4C8G × 3 | Docker容器 | 内网访问 |
| 测试环境 | 功能测试 | 8C16G × 5 | Kubernetes集群 | 内网访问 |
| 预生产环境 | 性能测试 | 16C32G × 8 | Kubernetes集群 | VPN访问 |
| 生产环境 | 正式运行 | 32C64G × 10+ | Kubernetes集群 | CDN+SSL |

### 3.2 服务器规划
#### 3.2.1 生产环境服务器
| 角色 | 数量 | 配置 | 用途 |
|------|------|------|------|
| 应用服务器 | 10+ | 32C64G 1TB SSD | 微服务部署 |
| 数据库服务器 | 6 | 64C128G 2TB SSD | MySQL主从 |
| 缓存服务器 | 6 | 32C64G 256GB | Redis集群 |
| 消息队列服务器 | 4 | 16C32G 512GB SSD | RocketMQ集群 |
| 监控服务器 | 3 | 8C16G 500GB | 监控系统 |
| 存储服务器 | 3 | 32C64G 4TB HDD | 文件存储 |

## 4. 容器化部署

### 4.1 Docker镜像设计
```dockerfile
# 基础镜像
FROM openjdk:17-jre-slim

# 安装必要的工具
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    tzdata \
    && rm -rf /var/lib/apt/lists/*

# 设置时区
ENV TZ=Asia/Shanghai

# 创建应用用户
RUN groupadd -r appuser && useradd -r -g appuser appuser

# 创建工作目录
WORKDIR /app

# 复制应用文件
COPY target/*.jar app.jar

# 设置权限
RUN chown -R appuser:appuser /app

# 切换用户
USER appuser

# 健康检查
HEALTHCHECK --interval=30s --timeout=3s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8080/actuator/health || exit 1

# 暴露端口
EXPOSE 8080

# 启动命令
CMD ["java", "-jar", "app.jar", "--spring.profiles.active=prod"]
```

### 4.2 Docker Compose配置
```yaml
version: '3.8'

services:
  # MySQL数据库
  mysql-master:
    image: mysql:8.0
    container_name: mysql-master
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: cex_db
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    volumes:
      - mysql-master-data:/var/lib/mysql
      - ./config/mysql/master.cnf:/etc/mysql/conf.d/master.cnf
    ports:
      - "3306:3306"
    networks:
      - cex-network
    restart: unless-stopped

  mysql-slave:
    image: mysql:8.0
    container_name: mysql-slave
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: cex_db
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    volumes:
      - mysql-slave-data:/var/lib/mysql
      - ./config/mysql/slave.cnf:/etc/mysql/conf.d/slave.cnf
    ports:
      - "3307:3306"
    networks:
      - cex-network
    restart: unless-stopped
    depends_on:
      - mysql-master

  # Redis集群
  redis-node1:
    image: redis:7-alpine
    container_name: redis-node1
    command: redis-server /etc/redis/redis.conf
    volumes:
      - ./config/redis/redis-node1.conf:/etc/redis/redis.conf
      - redis-node1-data:/data
    ports:
      - "6379:6379"
    networks:
      - cex-network
    restart: unless-stopped

  redis-node2:
    image: redis:7-alpine
    container_name: redis-node2
    command: redis-server /etc/redis/redis.conf
    volumes:
      - ./config/redis/redis-node2.conf:/etc/redis/redis.conf
      - redis-node2-data:/data
    ports:
      - "6380:6379"
    networks:
      - cex-network
    restart: unless-stopped

  redis-node3:
    image: redis:7-alpine
    container_name: redis-node3
    command: redis-server /etc/redis/redis.conf
    volumes:
      - ./config/redis/redis-node3.conf:/etc/redis/redis.conf
      - redis-node3-data:/data
    ports:
      - "6381:6379"
    networks:
      - cex-network
    restart: unless-stopped

  # RocketMQ
  rocketmq-nameserver:
    image: apache/rocketmq:4.9.4
    container_name: rocketmq-nameserver
    command: sh mqnamesrv
    volumes:
      - rocketmq-nameserver-logs:/home/rocketmq/logs
    ports:
      - "9876:9876"
    networks:
      - cex-network
    restart: unless-stopped

  rocketmq-broker-a:
    image: apache/rocketmq:4.9.4
    container_name: rocketmq-broker-a
    command: sh mqbroker -n rocketmq-nameserver:9876 -c /etc/rocketmq/broker-a.conf
    volumes:
      - rocketmq-broker-a-logs:/home/rocketmq/logs
      - rocketmq-broker-a-store:/home/rocketmq/store
      - ./config/rocketmq/broker-a.conf:/etc/rocketmq/broker-a.conf
    ports:
      - "10909:10909"
      - "10911:10911"
    networks:
      - cex-network
    restart: unless-stopped
    depends_on:
      - rocketmq-nameserver

  # Nacos
  nacos:
    image: nacos/nacos-server:2.2.3
    container_name: nacos
    environment:
      MODE: cluster
      SPRING_DATASOURCE_PLATFORM: mysql
      MYSQL_SERVICE_HOST: mysql-master
      MYSQL_SERVICE_PORT: 3306
      MYSQL_SERVICE_DB_NAME: nacos
      MYSQL_SERVICE_USER: ${MYSQL_USER}
      MYSQL_SERVICE_PASSWORD: ${MYSQL_PASSWORD}
    volumes:
      - nacos-logs:/home/nacos/logs
    ports:
      - "8848:8848"
    networks:
      - cex-network
    restart: unless-stopped
    depends_on:
      - mysql-master

  # 应用服务
  user-service:
    build: ./backend/user-service
    container_name: user-service
    environment:
      SPRING_PROFILES_ACTIVE: prod
      NACOS_SERVER_ADDR: nacos:8848
      ROCKETMQ_NAME_SERVER_ADDR: rocketmq-nameserver:9876
    ports:
      - "8001:8080"
    networks:
      - cex-network
    restart: unless-stopped
    depends_on:
      - mysql-master
      - redis-node1
      - rocketmq-nameserver
      - nacos

  trade-service:
    build: ./backend/trade-service
    container_name: trade-service
    environment:
      SPRING_PROFILES_ACTIVE: prod
      NACOS_SERVER_ADDR: nacos:8848
      ROCKETMQ_NAME_SERVER_ADDR: rocketmq-nameserver:9876
    ports:
      - "8002:8080"
    networks:
      - cex-network
    restart: unless-stopped
    depends_on:
      - mysql-master
      - redis-node1
      - rocketmq-nameserver
      - nacos

  # Nginx
  nginx:
    image: nginx:alpine
    container_name: nginx
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./config/nginx/ssl:/etc/nginx/ssl
    ports:
      - "80:80"
      - "443:443"
    networks:
      - cex-network
    restart: unless-stopped
    depends_on:
      - user-service
      - trade-service

volumes:
  mysql-master-data:
  mysql-slave-data:
  redis-node1-data:
  redis-node2-data:
  redis-node3-data:
  rocketmq-nameserver-logs:
  rocketmq-broker-a-logs:
  rocketmq-broker-a-store:
  nacos-logs:

networks:
  cex-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

## 5. Kubernetes部署

### 5.1 命名空间配置
```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: cex-system
  labels:
    name: cex-system
---
apiVersion: v1
kind: Namespace
metadata:
  name: cex-app
  labels:
    name: cex-app
---
apiVersion: v1
kind: Namespace
metadata:
  name: cex-data
  labels:
    name: cex-data
---
apiVersion: v1
kind: Namespace
metadata:
  name: cex-monitoring
  labels:
    name: cex-monitoring
```

### 5.2 配置映射
```yaml
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: cex-app
data:
  application.yml: |
    spring:
      profiles:
        active: prod
      cloud:
        nacos:
          discovery:
            server-addr: nacos:8848
            namespace: cex-app
        sentinel:
          transport:
            dashboard: sentinel:8080
      redis:
        cluster:
          nodes:
            - redis-node1:6379
            - redis-node2:6379
            - redis-node3:6379
      rocketmq:
        name-server: rocketmq-nameserver:9876
    server:
      port: 8080
    management:
      endpoints:
        web:
          exposure:
            include: health,info,metrics
```

### 5.3 密钥配置
```yaml
# secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secret
  namespace: cex-app
type: Opaque
data:
  mysql-password: ${BASE64_MYSQL_PASSWORD}
  redis-password: ${BASE64_REDIS_PASSWORD}
  jwt-secret: ${BASE64_JWT_SECRET}
  api-key: ${BASE64_API_KEY}
  api-secret: ${BASE64_API_SECRET}
```

### 5.4 应用部署
```yaml
# user-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  namespace: cex-app
  labels:
    app: user-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
    spec:
      containers:
      - name: user-service
        image: cex/user-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: NACOS_SERVER_ADDR
          value: "nacos:8848"
        - name: ROCKETMQ_NAME_SERVER_ADDR
          value: "rocketmq-nameserver:9876"
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: user-service
  namespace: cex-app
  labels:
    app: user-service
spec:
  selector:
    app: user-service
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP
```

### 5.5 Ingress配置
```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: cex-ingress
  namespace: cex-app
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - api.example.com
    secretName: example-com-tls
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /user
        pathType: Prefix
        backend:
          service:
            name: user-service
            port:
              number: 80
      - path: /trade
        pathType: Prefix
        backend:
          service:
            name: trade-service
            port:
              number: 80
      - path: /wallet
        pathType: Prefix
        backend:
          service:
            name: wallet-service
            port:
              number: 80
```

## 6. 持续集成/持续部署

### 6.1 CI/CD流程图
```
代码提交 → 自动构建 → 单元测试 → 代码扫描 → 构建镜像 → 推送到仓库 → 部署到测试环境 → 集成测试 → 部署到预生产 → 性能测试 → 部署到生产环境
```

### 6.2 Jenkins流水线
```groovy
pipeline {
    agent any

    environment {
        REGISTRY = 'registry.example.com'
        REPOSITORY = 'cex/user-service'
        TAG = "${env.BUILD_ID}"
    }

    stages {
        stage('Checkout') {
            steps {
                git url: 'https://github.com/your-org/cex.git', branch: 'main'
            }
        }

        stage('Build') {
            steps {
                sh 'mvn clean package -DskipTests'
            }
        }

        stage('Test') {
            steps {
                sh 'mvn test'
                publishTestResults testResultsPattern: '**/target/surefire-reports/*.xml'
            }
        }

        stage('Code Scan') {
            steps {
                sh 'mvn sonar:sonar'
            }
        }

        stage('Build Image') {
            steps {
                script {
                    docker.build("${REPOSITORY}:${TAG}")
                }
            }
        }

        stage('Push Image') {
            steps {
                script {
                    docker.withRegistry("https://${REGISTRY}", 'docker-credentials') {
                        docker.image("${REPOSITORY}:${TAG}").push()
                        docker.image("${REPOSITORY}:${TAG}").push('latest')
                    }
                }
            }
        }

        stage('Deploy to Test') {
            steps {
                kubernetesDeploy(
                    configs: 'k8s/test/*.yaml',
                    kubeconfigId: 'k8s-test'
                )
            }
        }

        stage('Integration Test') {
            steps {
                sh './scripts/integration-test.sh'
            }
        }

        stage('Deploy to Staging') {
            when {
                branch 'main'
            }
            steps {
                kubernetesDeploy(
                    configs: 'k8s/staging/*.yaml',
                    kubeconfigId: 'k8s-staging'
                )
            }
        }

        stage('Performance Test') {
            when {
                branch 'main'
            }
            steps {
                sh './scripts/performance-test.sh'
            }
        }

        stage('Deploy to Production') {
            when {
                branch 'main'
            }
            steps {
                input message: 'Deploy to Production?', ok: 'Deploy'
                kubernetesDeploy(
                    configs: 'k8s/production/*.yaml',
                    kubeconfigId: 'k8s-production'
                )
            }
        }
    }

    post {
        always {
            echo 'Pipeline completed'
            cleanWs()
        }
    }
}
```

### 6.3 GitLab CI配置
```yaml
# .gitlab-ci.yml
stages:
  - build
  - test
  - scan
  - deploy
  - integration
  - performance

variables:
  DOCKER_REGISTRY: registry.example.com
  DOCKER_IMAGE: $DOCKER_REGISTRY/cex/user-service

cache:
  paths:
    - .m2/repository

build:
  stage: build
  image: maven:3.8-openjdk-17
  script:
    - mvn clean package -DskipTests
  artifacts:
    paths:
      - target/*.jar

test:
  stage: test
  image: maven:3.8-openjdk-17
  script:
    - mvn test
  coverage: '/Line coverage: \d+\.\d+%/'
  artifacts:
    reports:
      junit:
        - target/surefire-reports/*.xml

sonar-scan:
  stage: scan
  image: maven:3.8-openjdk-17
  script:
    - mvn sonar:sonar
  only:
    - main
    - develop

docker-build:
  stage: deploy
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker build -t $DOCKER_IMAGE:$CI_COMMIT_SHA .
    - docker push $DOCKER_IMAGE:$CI_COMMIT_SHA
    - docker tag $DOCKER_IMAGE:$CI_COMMIT_SHA $DOCKER_IMAGE:latest
    - docker push $DOCKER_IMAGE:latest

deploy-test:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context test-cluster
    - kubectl apply -f k8s/test/
    - kubectl set image deployment/user-service user-service=$DOCKER_IMAGE:$CI_COMMIT_SHA
  only:
    - main
    - develop

integration-test:
  stage: integration
  image: maven:3.8-openjdk-17
  script:
    - mvn verify -Pintegration-test
  only:
    - main
    - develop

deploy-staging:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context staging-cluster
    - kubectl apply -f k8s/staging/
    - kubectl set image deployment/user-service user-service=$DOCKER_IMAGE:$CI_COMMIT_SHA
  when: manual
  only:
    - main

performance-test:
  stage: performance
  image: alpine:latest
  script:
    - apk add --no-cache curl
    - ./scripts/performance-test.sh
  only:
    - main

deploy-production:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context production-cluster
    - kubectl apply -f k8s/production/
    - kubectl set image deployment/user-service user-service=$DOCKER_IMAGE:$CI_COMMIT_SHA
  when: manual
  only:
    - main
```

## 7. 监控配置

### 7.1 Prometheus配置
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
      - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

  - job_name: 'kubernetes-nodes'
    kubernetes_sd_configs:
      - role: node
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
```

### 7.2 Grafana仪表盘
```json
{
  "dashboard": {
    "id": null,
    "title": "CEX System Overview",
    "tags": ["cex", "monitoring"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "System CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "{{instance}}"
          }
        ],
        "yaxes": [
          {
            "format": "percent",
            "min": 0,
            "max": 100
          }
        ]
      },
      {
        "id": 2,
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100",
            "legendFormat": "{{instance}}"
          }
        ],
        "yaxes": [
          {
            "format": "percent",
            "min": 0,
            "max": 100
          }
        ]
      },
      {
        "id": 3,
        "title": "JVM Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "jvm_memory_bytes_used{area=\"heap\"} / jvm_memory_bytes_max{area=\"heap\"} * 100",
            "legendFormat": "{{app}} - {{instance}}"
          }
        ],
        "yaxes": [
          {
            "format": "percent",
            "min": 0,
            "max": 100
          }
        ]
      },
      {
        "id": 4,
        "title": "HTTP Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}} {{path}}"
          }
        ]
      },
      {
        "id": 5,
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "{{method}} {{path}}"
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "10s"
  }
}
```

## 8. 日志管理

### 8.1 ELK Stack配置
```yaml
# elasticsearch.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    volumes:
      - ./config/logstash/pipeline.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.8.0
    volumes:
      - ./config/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/log:/var/log
    depends_on:
      - elasticsearch
      - logstash

volumes:
  elasticsearch-data:
```

### 8.2 Filebeat配置
```yaml
# filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/cex/*.log
  fields:
    app: cex
    env: production

output.logstash:
  hosts: ["logstash:5044"]

logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

### 8.3 Logstash配置
```conf
# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][app] == "cex" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:logger} - %{GREEDYDATA:message}" }
    }

    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
    }

    if [level] == "ERROR" {
      aggregate {
        task_id => "%{host}%{timestamp}"
        code => "map['error_count'] ||= 0; map['error_count'] += 1"
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "cex-%{+YYYY.MM.dd}"
  }

  stdout {
    codec => rubydebug
  }
}
```

## 9. 备份策略

### 9.1 数据库备份
```bash
#!/bin/bash
# database_backup.sh

BACKUP_DIR="/backup/mysql"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/mysql_backup_${DATE}.sql.gz"
RETENTION_DAYS=7

# 创建备份目录
mkdir -p $BACKUP_DIR

# 执行备份
mysqldump -h mysql-master -u root -p$MYSQL_ROOT_PASSWORD \
  --single-transaction --routines --triggers --all-databases | \
  gzip > $BACKUP_FILE

# 验证备份
if [ $? -eq 0 ]; then
  echo "Database backup successful: $BACKUP_FILE"

  # 上传到云存储
  aws s3 cp $BACKUP_FILE s3://backup-bucket/mysql/

  # 清理旧备份
  find $BACKUP_DIR -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete
else
  echo "Database backup failed"
  exit 1
fi
```

### 9.2 Redis备份
```bash
#!/bin/bash
# redis_backup.sh

BACKUP_DIR="/backup/redis"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/redis_backup_${DATE}.rdb"
RETENTION_DAYS=7

# 创建备份目录
mkdir -p $BACKUP_DIR

# 执行备份
redis-cli --rdb $BACKUP_FILE

# 验证备份
if [ -f $BACKUP_FILE ]; then
  echo "Redis backup successful: $BACKUP_FILE"

  # 上传到云存储
  aws s3 cp $BACKUP_FILE s3://backup-bucket/redis/

  # 清理旧备份
  find $BACKUP_DIR -name "*.rdb" -mtime +$RETENTION_DAYS -delete
else
  echo "Redis backup failed"
  exit 1
fi
```

### 9.3 应用配置备份
```bash
#!/bin/bash
# config_backup.sh

BACKUP_DIR="/backup/config"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/config_backup_${DATE}.tar.gz"
RETENTION_DAYS=30

# 创建备份目录
mkdir -p $BACKUP_DIR

# 执行备份
tar -czf $BACKUP_FILE \
  /etc/nginx \
  /etc/redis \
  /opt/rocketmq/conf \
  /opt/nacos/conf

# 验证备份
if [ $? -eq 0 ]; then
  echo "Configuration backup successful: $BACKUP_FILE"

  # 上传到云存储
  aws s3 cp $BACKUP_FILE s3://backup-bucket/config/

  # 清理旧备份
  find $BACKUP_DIR -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete
else
  echo "Configuration backup failed"
  exit 1
fi
```

## 10. 灾难恢复

### 10.1 灾备切换流程
```bash
#!/bin/bash
# disaster_recovery.sh

# 灾备切换主函数
function disaster_recovery() {
  echo "Starting disaster recovery process..."

  # 1. 检查主集群状态
  check_primary_cluster

  # 2. 切换DNS到灾备集群
  switch_dns_to_backup

  # 3. 启动灾备集群
  start_backup_cluster

  # 4. 验证服务
  verify_services

  # 5. 通知相关人员
  notify_stakeholders

  echo "Disaster recovery completed"
}

# 检查主集群状态
function check_primary_cluster() {
  echo "Checking primary cluster status..."

  # 检查API服务
  if ! curl -f http://api.example.com/health; then
    echo "Primary API service is down"
    return 1
  fi

  # 检查数据库
  if ! mysql -h mysql-master -u root -p$MYSQL_ROOT_PASSWORD -e "SELECT 1"; then
    echo "Primary database is down"
    return 1
  fi

  echo "Primary cluster is healthy"
}

# 切换DNS
function switch_dns_to_backup() {
  echo "Switching DNS to backup cluster..."

  # 更新DNS记录
  aws route53 change-resource-record-sets \
    --hosted-zone-id Z1D633PEXAMPLE \
    --change-batch file://dns-change.json

  # 等待DNS生效
  sleep 300

  echo "DNS switch completed"
}

# 启动灾备集群
function start_backup_cluster() {
  echo "Starting backup cluster..."

  # 启动Kubernetes服务
  kubectl config use-context backup-cluster
  kubectl scale deployment --replicas=3 --all

  # 等待服务启动
  kubectl wait --for=condition=ready pod --all --timeout=300s

  echo "Backup cluster started"
}

# 验证服务
function verify_services() {
  echo "Verifying services..."

  # 检查API服务
  if ! curl -f http://backup-api.example.com/health; then
    echo "Backup API service verification failed"
    return 1
  fi

  # 检查数据库
  if ! mysql -h backup-mysql-master -u root -p$MYSQL_ROOT_PASSWORD -e "SELECT 1"; then
    echo "Backup database verification failed"
    return 1
  fi

  echo "All services verified"
}

# 通知相关人员
function notify_stakeholders() {
  echo "Notifying stakeholders..."

  # 发送邮件通知
  send_email_notification

  # 发送短信通知
  send_sms_notification

  # 发送Slack通知
  send_slack_notification

  echo "Notifications sent"
}

# 主函数
main() {
  disaster_recovery
}

main "$@"
```

## 11. 运维手册

### 11.1 日常运维检查清单
- [ ] 检查服务器CPU和内存使用率
- [ ] 检查磁盘空间使用情况
- [ ] 检查网络连接状态
- [ ] 检查数据库主从同步状态
- [ ] 检查Redis集群状态
- [ ] 检查RocketMQ消息堆积情况
- [ ] 检查应用服务运行状态
- [ ] 检查备份任务执行情况
- [ ] 检查监控系统告警
- [ ] 检查日志系统运行状态

### 11.2 故障处理流程
1. **故障发现**: 监控系统自动告警
2. **故障评估**: 评估故障影响范围
3. **故障定位**: 通过日志和监控定位问题
4. **故障处理**: 执行相应的故障处理方案
5. **故障恢复**: 恢复系统正常运行
6. **故障总结**: 分析故障原因，制定改进措施

### 11.3 性能调优
- **JVM调优**: 根据监控数据调整JVM参数
- **数据库调优**: 优化SQL语句，调整数据库配置
- **缓存调优**: 调整Redis缓存策略
- **网络调优**: 优化网络配置，提高网络性能
- **应用调优**: 优化应用代码，提高处理效率

## 12. 安全加固

### 12.1 系统安全加固
- 操作系统补丁更新
- 防火墙配置
- SSH安全配置
- 用户权限管理
- 服务进程权限控制

### 12.2 应用安全加固
- 依赖库安全检查
- 代码安全扫描
- 配置文件安全
- API接口安全
- 数据传输加密

### 12.3 网络安全加固
- 网络隔离
- 访问控制
- 入侵检测
- 流量监控
- 安全审计